package handlers

import (
	"context"
	"core-ledger/pkg/queue"
	"core-ledger/pkg/queue/jobs"
	"core-ledger/pkg/repo"
	"fmt"
	"log"
	"time"

	"github.com/hibiken/asynq"
)

// DataProcessHandler x·ª≠ l√Ω DataProcessJob
type DataProcessHandler struct {
	repo.TransactionRepo
	dispatcher queue.Dispatcher

	// th√™m dependency n·∫øu c·∫ßn (v√≠ d·ª•: services, repos)
}

func NewDataProcessHandler(transactionRepo repo.TransactionRepo, dispatcher queue.Dispatcher) *DataProcessHandler {
	return &DataProcessHandler{
		TransactionRepo: transactionRepo,
		dispatcher:      dispatcher,
	}
}

// NewDataProcessRegistration: provider ƒëƒÉng k√Ω job/handler v√†o group "queue-registrations"
func NewDataProcessRegistration(h *DataProcessHandler) queue.Registration {
	return queue.Registration{
		Type:     "data:process",
		Template: &jobs.DataProcessJob{},
		Handler:  h,
	}
}

func (h *DataProcessHandler) Handle(ctx context.Context, j queue.Job) error {
	// ki·ªÉu assert v·ªÅ concrete job
	job, ok := j.(*jobs.DataProcessJob)
	if !ok {
		return fmt.Errorf("invalid job type, expect *DataProcessJob")
	}

	// Log retry info
	currentAttempt := 1
	if n, ok := asynq.GetRetryCount(ctx); ok {
		currentAttempt = n + 1
	}
	maxRetry := 0
	if max, ok := asynq.GetMaxRetry(ctx); ok {
		maxRetry = max
	}

	// Log backoff info n·∫øu c√≥
	backoff := job.GetBackoff()
	backoffInfo := "none (using default)"
	if len(backoff) > 0 {
		backoffInfo = fmt.Sprintf("%v seconds", backoff)
	}

	log.Printf("üì¶ [Job] Handling DataProcessJob: Type=%s, Action=%s | Attempt=%d/%d | Backoff=%s",
		job.ProcessType, job.Action, currentAttempt, maxRetry+1, backoffInfo)

	// Test l·ªói: ƒë·∫∑t Action="fail" ƒë·ªÉ c·ªë t√¨nh tr·∫£ v·ªÅ l·ªói (k√≠ch ho·∫°t retry/Failed)
	if job.Action == "fail" {
		log.Printf("‚ùå [Job] Forcing failure for testing (will retry with backoff)")
		return fmt.Errorf("forced failure for testing")
	}

	dataJob := jobs.NewMyJob("user_analytics", "export", map[string]interface{}{
		"user_id": "test_user_123",
		"format":  "json",
		"filters": map[string]interface{}{
			"date_from": "2024-01-01",
			"date_to":   "2024-12-31",
			"status":    "active",
		},
	})

	dataJob.SetOptions(map[string]interface{}{
		"include_headers": true,
		"date_format":     "ISO",
		"compression":     "none",
		"max_records":     1000,
	})
	dataJob.SetQueue("critical")
	if err := h.dispatcher.Dispatch(dataJob, queue.Timeout(1*time.Second)); err != nil {
		log.Printf("‚ùå Failed to dispatch data job: %v", err)
		return err
	}
	// var transactions []model.Transaction
	// transactions, err := h.TransactionRepo.GetList(ctx)
	// log.Printf("Fetched %d transactions", len(transactions))
	// if err != nil {
	// 	return err
	// }
	// TODO: business logic x·ª≠ l√Ω theo job.ProcessType / job.Action / job.Data

	return nil // tr·∫£ v·ªÅ error ƒë·ªÉ asynq retry n·∫øu c·∫ßn
}

// Failed: hook ƒë∆∞·ª£c g·ªçi khi job ƒë√£ h·∫øt retry ho·∫∑c timeout
func (h *DataProcessHandler) Failed(ctx context.Context, j queue.Job, err error) {
	// c·ªë g·∫Øng assert ƒë√∫ng lo·∫°i job ƒë·ªÉ log chi ti·∫øt
	if job, ok := j.(*jobs.DataProcessJob); ok {
		log.Printf("[FAILED] DataProcessJob Type=%s Action=%s Error=%v", job.ProcessType, job.Action, err)
	} else {
		log.Printf("[FAILED] DataProcessJob Error=%v", err)
	}
	// TODO: C√≥ th·ªÉ ghi log v√†o DB, t·∫°o transaction_log, ho·∫∑c ƒë·∫©y sang channel c·∫£nh b√°o...
	_ = h // gi·ªØ ch·ªó n·∫øu sau n√†y c·∫ßn d√πng repo ƒë·ªÉ l∆∞u DB
}
